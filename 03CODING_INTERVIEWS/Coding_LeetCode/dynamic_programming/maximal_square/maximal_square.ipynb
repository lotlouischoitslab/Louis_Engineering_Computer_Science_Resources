{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b185b6ab",
   "metadata": {},
   "source": [
    "### https://leetcode.com/problems/maximal-square/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd9e9f6",
   "metadata": {},
   "source": [
    "### Important Note here 'self' means global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753de339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Solution:\n",
    "#     def maximalSquare(self, matrix: List[List[str]]) -> int:\n",
    "#         def dp(row,col,matrix,cache):\n",
    "            \n",
    "#             if row >= len(matrix) or col >= len(matrix[0]):\n",
    "#                 return 0\n",
    "            \n",
    "#             if (row,col) in cache:\n",
    "#                 return cache[(row,col)]\n",
    "            \n",
    "#             bottom_neighbor = dp(row + 1,col,matrix,cache)\n",
    "#             right_neighbor = dp(row, col + 1, matrix, cache)\n",
    "#             bottom_right_neighbor = dp(row + 1,col + 1,matrix,cache)\n",
    "           \n",
    "#             if matrix[row][col] == '0':\n",
    "#                 cache[(row,col)] = 0\n",
    "#             else: \n",
    "#                 self.max_size_len = max(self.max_size_len, min(bottom_neighbor,right_neighbor, bottom_right_neighbor)+1) \n",
    "#                 cache[(row,col)] = min(bottom_neighbor, right_neighbor, bottom_right_neighbor) + 1\n",
    "#             return cache[(row,col)]\n",
    "        \n",
    "        \n",
    "#         cache = dict()\n",
    "#         self.max_size_len = 0 \n",
    "#         (dp(0,0,matrix,cache))**2\n",
    "#         return self.max_size_len**2\n",
    "\n",
    "        \n",
    "#Top-Down Approach (Memoization):\n",
    "#State Variables: row and col index representing the row and column, respectively, of the current matrix entry (which we can visualize as the top left corner of a potential square of only 1's). \n",
    "\n",
    "#1. A function or data structure to compute/hold the answer to the problem for every state.\n",
    "#In the case of the top down approach, we will have a function dp that will compute the area of the largest square containing only 1's starting from the current matrix entry (matrix[row][col]) as the top left corner of the submatrix. Let's cache our intermediate results for each of our subproblems by mapping a tuple as a key containing the row and column indices of the current matrix entry to the area of the largest square containing only 1's of the submatrix with the matrix entry at position row in the 1st dimension and col in the 2nd dimension as the top left corner. So, whenever we encounter duplicate inputs, we can perform a hashmap lookup in constant time as opposed to using our recurrence relation and invoking the recursive function on the right, bottom, and bottom-right neighbors of the current matrix entry once again. This will reduce the time complexity from O(3^(M*N)) where 3 is our branching factor because for each recursive call, we make 3 additional recursive calls everytime we implement our recurrence relation where M*N is the total number of entries in the matrix. It will be reduced to O(M*N) since we prune out the additional recursive calls everytime we encounter the same row and column inputs to our dp function. We will also store the maximum side length in a global variable so that we don't lose this information as we execute the recursive calls in LIFO order starting from the base case. If we ever discover a subproblem result that exceeds the maximum side length that we are storing thus far, we will replace the maximum side length's value with the subproblem results (an int representing the side length of the largest square containing only 1's inside the entire matrix). \n",
    "\n",
    "#2. A recurrence relation to transition between the states.\n",
    "#As we mentioned above, we will explore the neighbors to the right, bottom, and bottom-right of the current matrix entry and combine the results of these subproblems to figure out the result for our problem, or the area of the largest square containing only 1's of the matrix with the current matrix entry in its top-left corner. So, call the recursive function dp and increment the column in order to compute the largest square containing only 1's of the matrix with the right neighbor of the current matrix entry as the top-left corner of that respective submatrix. Likewise, invoke dp and increment the row for the bottom neighbor. Lastly, invoke dp and increment both the row and column index for the bottom-right neighbor. If any of these subproblem results yields a 0, and the current matrix entry is a 1, then return 1 since the largest square containing only 1's that we can make is the square containing only the current matrix entry given that one of its neighbors is a 0. Otherwise, if all the subproblems results are non-zero and equal, return 1 + any of the subproblem results (since they are all the same). This means that the current matrix entry becomes the new top left corner of an even larger square containing only 1's. We know that the neighbors of the current matrix entry themselves are squares with a side length of at least 1. Notice that we are only accumulating the side lenghts of the largest square starting from the current matrix entry at the top left corner, so to obtain the area of the largest square, we will need to square the result at the ver yend, so we will only square the result of any one of the subproblems are not equal to the other subproblem results but they are all non zero, then return the minimum subproblem result + 1. This is because we only know that we contribute 1 to the neighbor containing the neighbor whose result is the smallest compared to other neighbor's result. So whichever of the neighbors return the smalleset side length for the largest square it has found with neighbors, we will contribute 1 and because the new top left corner of that previous submatrix square. Otherwise, if any one of the subproblems results are not equal to the other subproblem results but they are all non-zero, then return the minimum subproblem + 1 result (or the max result from calling dp on each of the current matrix entry's neighbors). This is because we only know that the current matrix entry is adding 1 to the side length of the largest square containing only 1's of the submatrix representing the minimum subproblem. \n",
    "\n",
    "#3. Base case to stop recursion\n",
    "# If the current entry is out of bounds for the matrix's number of rows or number of columns, then return 0. \n",
    "\n",
    "#Runtime Analysis: O(M*N) where M is the number of rows and N is the number of columns. We will do a full traversal of the matrix in the general case. Regardless of whether the current matrix entry at position row in the 1st dimension and col in the 2nd dimension is a 1 or not, we will consider the neighbors as subproblems and use the results of these subproblems in order to figure out what to return as the result for the larger problem. If we try visiting a neighbor that we have already visited, then we should already have the side length for the largest square containing only 1's stored inside a cache and be ready to retirve the value immediately, resolve that recursive call. Otherwise, we will use our recurrence relation to visit the right, bottom, and bottom-right neighbors of the current matrix entry, thereby visiting every entry of the matrix by the time we have completely cleared up our recursion stack and resolved all recursive calls. Therefore, the time comlpexity for this algorithm is O(M*N). \n",
    "\n",
    "#Space Complexity: O(M*N). This is proportional to our runtime. We will keep adding the neighbors of the current matrix which become the new current matrix entry all the may until we hit a base case and then start executing the recursive calls in LIFO order. We may not be able to resolve all recursive calls at once in our recursion stack (just whichever were considered neighbors and neighbors of the neighbors of the matrix entry at the base case). So, as we execute these recursive calls in LIFO order, we will have the results of our subproblems really so that we can combine them together to figure out the result of the overarching problem. Theresore, our overall memory usage is O(M*N) \n",
    "\n",
    "\n",
    "#Bottom-Up Approach (Tabulation)\n",
    "#1. A function or data structure to compute/hold the answer to the problem for every state\n",
    "#2. In the case of the bottom-up approach, we'll have a 2d array dp since our dp problem is a two-dimensional problem with two state variables: row and col. The first dimension of the 2d array will reprresent the row index in the first dimension of the input matrix. The second dimension of the 2d array will represent the column index in the second dimension of the input matrix. We will need to iterate backwards since we need to have the results from our subproblems immediately ready by the time we figure out the result of a larger, overarching problem. Also, notice from the top-down approach that we call our function dp on the right neighbor (by incrementing the col index by 1), bottom neighbor (by incrementing the row index by 1), and the bottom-right neighbor (by incrementing both the row and col index by 1). To convert from the memoization approach to our tabulation approach, we will convert these recursion calls into array lookups, meaning we will need to combine the results from dp[row+1][col], dp[row][col + 1], dp[row+1][col+1] in order to figure out the side length of the largest square containing only 1's for the submatrix/matrix with its top-left corner positioning at the current matrix entry matrix[row][col]. By iterating backwards from the very last row to the first row in the outer loop and the very last column to the first column in the inner loop, we will have the subproblem results ready by the time we want to fill our 2d array dp value at position row in the 1st dimension and col in the 2nd dimension. Similar to the top-down approach, we will maintain the maximum side length as a global variable so that we don't lose this piece of information as we iterate backwards starting from dp[row][col] all the way to dp[0][0]. Notice that since we start our last row and column to represent the base case since they would be out of bounds for the input matrix's number of rows and columns, so our 2d array dp will need to have a size 1 greater than the input matrix's size in both the 1st dimension and 2nd dimension.\n",
    "\n",
    "#2. A recurrence relation to transition between states. \n",
    "# If the current matrix entry is a '0', return 0 since we cannot form  a square containing only 1's when a 0 would be the top-left corner of this potential square. \n",
    "\n",
    "#If the neighbor subproblem results are all non-zero and equal, return 1 + any of the subproblem results for the reason stated in the top-down approach. If any of the neighbor subproblems yields to 0, return 1 for the reason stated in the top-down approach.\n",
    "#If any of the neighbor subproblem results are not equal to the other ones but all are non-zero, return 1 + the minimum of the subproblem results for the reason stated in the top-down approach. \n",
    "\n",
    "#3. Base Case to stop recursion:\n",
    "#Same as above except we will now account for the base case by adding an additional row and column to our matrix dp when comparing to the original matrix and initialized all those entries to 0's so that we can start iterating backwards but keep all the out of bounds entries as 0's since we cannot form a square containing only 1's when our index is not inside the original matrix itself. \n",
    "\n",
    "#Runtime Complexity: O(M*N) where M is the number of rows of the input matrix and n is the number of columns of the input matrix. We iterate backwards for m + 1 iterations of the outer loop and m + 1 iterations of the inner loop so that we can visit every entry of the 2d array dp. So our runtime will be proportional to the number of entries in our 2d array dp.\n",
    "\n",
    "# Space Complexity: O(M*N) Proportional to runtime complexity. This should be somewhat intuitive as well since we have auxiliary data structure to store the intermediate and the original problem results of the side lengths of the largest square containing only 1's from the matrix/submatrix starting with the current matrix entry (matrix[row][col]) as the top-left corner of the square. The 2d array dp can store n + 1 vectors in the first dimension and n + 1 entries in the second dimension. We can ignore constants in Big-O expressions our overall memory usage is O(M*N). \n",
    "    \n",
    "    \n",
    "# Bottom-Up Approach (Tabulation)\n",
    "# class Solution:\n",
    "#     def maximalSquare(self, matrix: List[List[str]]) -> int:\n",
    "#         dp = []\n",
    "#         max_side_len = 0\n",
    "#         for i in range(len(matrix)+1):\n",
    "#             list = []\n",
    "#             for j in range(len(matrix[0])+1):\n",
    "#                 list.append(0)\n",
    "#             dp.append(list)\n",
    "        \n",
    "#         for row in range(len(matrix)-1,-1,-1):\n",
    "#             for col in range(len(matrix[0])-1,-1,-1):\n",
    "#                 if matrix[row][col] != '0':      \n",
    "#                     dp[row][col] = min(dp[row][col+1],dp[row+1][col],dp[row+1][col+1]) + 1\n",
    "#                     max_side_len = max(max_side_len,dp[row][col])\n",
    "                \n",
    "        \n",
    "#         return max_side_len**2\n",
    "    \n",
    "#Optimized Bottom-Up Approach\n",
    "#We can improve significantly on the space complexity. Notice that we store a complete 2d array dp with a size in fact 1 greater in the first dimension and second dimension than the original input matrix. However, notice that we only ever need the values for the side lengths of the largest square containing only 1's of the next row and our currnet row. We need to perform an array lookup of the right neighbor's result, so we need to store the result for the column right next to us but in the some row. The easiest thing we can do is maintain a 1d array for the current row so that at the end of the outer loop iteration prior to incrementing our loop index, we can assign the next row array to the current row array. We need the next row array to retrieve the subproblem results for the bottom neighbor and bottom-right neighbor since these values can only be stored and maintained in the next row, and without such an array, we lose this vital information for the recurrence relation. The size of both the current row array and the next row array will be the size of the 2d array dp that we maintain in the previous approach in its second dimension. So, it will be the input matrix's size in the second dimension + 1 so that we can store all of the column entries corresponding to the current row and next row. \n",
    "\n",
    "#Space Complexity: As we mentioned above, we have two 1d arrays with a size n. We can ignore coeefficients in our Big-O expressions so the overall memory usage is O(n). \n",
    "\n",
    "#Optimized Bottom-Up Approach\n",
    "\n",
    "class Solution:\n",
    "    def maximalSquare(self, matrix: List[List[str]]) -> int:\n",
    "        max_side_len = 0\n",
    "        next_row = [0] * (len(matrix[0]) + 1)\n",
    "        curr_row = [0] * (len(matrix[0]) + 1)\n",
    "        \n",
    "        for row in range(len(matrix) - 1,-1,-1):\n",
    "            for col in range(len(matrix[0]) - 1,-1,-1): \n",
    "                if matrix[row][col] == '0':\n",
    "                    curr_row[col] = 0\n",
    "                else:\n",
    "                    curr_row[col] = min(curr_row[col+1],next_row[col],next_row[col+1]) +1\n",
    "                    max_side_len = max(max_side_len,curr_row[col])\n",
    "            next_row,curr_row = curr_row,next_row\n",
    "            \n",
    "        return max_side_len**2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
